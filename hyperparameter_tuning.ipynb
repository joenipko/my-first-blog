{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from scipy.optimize import differential_evolution, NonlinearConstraint\n",
    "\n",
    "from utils import gen_data\n",
    "from optimum import objective\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miche\\OptionsAnalysis\\utils.py:61: FutureWarning: Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated. Combine the desired columns with pd.to_datetime after parsing instead.\n",
      "  target_dat = pd.read_csv(\n",
      "c:\\Users\\miche\\OptionsAnalysis\\utils.py:61: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  target_dat = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "target_dat = gen_data(\"C:\\\\Users\\\\miche\\\\Downloads\\\\trade-log-1030-4.csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'strategy': 'rand2bin', 'popsize': np.int64(12), 'mutation_low': 1.2796910002727695, 'mutation_high': 1.096850157946487, 'recombination': 0.6783331011414365}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'strategy': 'best1bin', 'popsize': np.int64(15), 'mutation_low': 0.833708611139022, 'mutation_high': 0.6428668179219408, 'recombination': 0.7603553891795412}\n",
      "Testing parameters: {'strategy': 'best1bin', 'popsize': np.int64(17), 'mutation_low': 1.4385527090157504, 'mutation_high': 0.5007787658410143, 'recombination': 0.8968846237164871}\n",
      "Testing parameters: {'strategy': 'best2bin', 'popsize': np.int64(16), 'mutation_low': 0.5070663052197174, 'mutation_high': 0.5230624250414158, 'recombination': 0.7099098641033557}\n",
      "Testing parameters: {'strategy': 'rand1bin', 'popsize': np.int64(10), 'mutation_low': 1.4737555188414593, 'mutation_high': 0.7327713404303042, 'recombination': 0.5362425738131283}\n",
      "Testing parameters: {'strategy': np.str_('best1bin'), 'popsize': np.int64(20), 'mutation_low': 1.5, 'mutation_high': 1.5, 'recombination': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'strategy': np.str_('rand1bin'), 'popsize': np.int64(10), 'mutation_low': 1.5, 'mutation_high': 0.5, 'recombination': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'strategy': np.str_('rand1bin'), 'popsize': np.int64(14), 'mutation_low': 1.1447412023445047, 'mutation_high': 0.9496922083469219, 'recombination': 0.5700171745077136}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'strategy': np.str_('best1bin'), 'popsize': np.int64(10), 'mutation_low': 1.2606712244808356, 'mutation_high': 0.546664859829212, 'recombination': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'strategy': np.str_('best1bin'), 'popsize': np.int64(18), 'mutation_low': 0.9592158068911133, 'mutation_high': 0.5149860280912674, 'recombination': 0.7962273839251244}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'strategy': np.str_('best1bin'), 'popsize': np.int64(17), 'mutation_low': 1.4056230603641346, 'mutation_high': 0.5404120906923608, 'recombination': 0.8657298505519666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'strategy': np.str_('rand2bin'), 'popsize': np.int64(17), 'mutation_low': 1.3993266622804321, 'mutation_high': 0.5, 'recombination': 0.8831498554666226}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'strategy': np.str_('best2bin'), 'popsize': np.int64(17), 'mutation_low': 1.4241519017754407, 'mutation_high': 0.5, 'recombination': 0.532569775492849}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'strategy': np.str_('rand1bin'), 'popsize': np.int64(16), 'mutation_low': 1.4135852958701145, 'mutation_high': 0.52258873832193, 'recombination': 0.662793202257139}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'strategy': np.str_('best2bin'), 'popsize': np.int64(16), 'mutation_low': 0.6982599456003323, 'mutation_high': 0.563376134660289, 'recombination': 0.731841796667879}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'strategy': np.str_('best1bin'), 'popsize': np.int64(17), 'mutation_low': 1.4730397078171427, 'mutation_high': 0.5195280835734702, 'recombination': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'strategy': np.str_('best1bin'), 'popsize': np.int64(16), 'mutation_low': 1.441728601892461, 'mutation_high': 0.5, 'recombination': 0.805991315243045}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'strategy': np.str_('rand1bin'), 'popsize': np.int64(17), 'mutation_low': 1.4234617856791525, 'mutation_high': 0.5593280242410981, 'recombination': 0.5780936934742351}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'strategy': np.str_('rand1bin'), 'popsize': np.int64(17), 'mutation_low': 1.4189262037758188, 'mutation_high': 0.6332901711836948, 'recombination': 0.6778865466993305}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'strategy': np.str_('best2bin'), 'popsize': np.int64(20), 'mutation_low': 0.5484116580275505, 'mutation_high': 1.4703110373197041, 'recombination': 0.895396826137137}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "C:\\Users\\miche\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters Found:\n",
      "{'strategy': 'best1bin', 'popsize': np.int64(17), 'mutation_low': 1.4385527090157504, 'mutation_high': 0.5007787658410143, 'recombination': 0.8968846237164871}\n",
      "Best Objective Function Value (WIN_RATE): 594.5645\n"
     ]
    }
   ],
   "source": [
    "bounds = [\n",
    "    (target_dat.VIX_ON_CHANGE.min(), target_dat.VIX_ON_CHANGE.max() - 0.01 ),  # VIX_overnight_min\n",
    "    (target_dat.VIX_ON_CHANGE.min() + 0.01, target_dat.VIX_ON_CHANGE.max()),  # VIX_overnight_max\n",
    "    (target_dat.SPX_ON_CHANGE.min(), target_dat.SPX_ON_CHANGE.max() -0.01),  # SPX_overnight_min\n",
    "    (target_dat.SPX_ON_CHANGE.min() + 0.01 , target_dat.SPX_ON_CHANGE.max()),  # SPX_overnight_max\n",
    "    (target_dat.VIX_CURRENT_CLOSE.min(), target_dat.VIX_CURRENT_CLOSE.max()-1),  # VIX_prior_min\n",
    "    (target_dat.VIX_CURRENT_CLOSE.min()+1, target_dat.VIX_CURRENT_CLOSE.max())  # VIX_prior_max\n",
    "]\n",
    "\n",
    "# Define constraints to ensure min is less than max for each range using NonlinearConstraint\n",
    "constraints = [\n",
    "    NonlinearConstraint(lambda x: x[1] - x[0], 0, np.inf),  # VIX_overnight_max > VIX_overnight_min\n",
    "    NonlinearConstraint(lambda x: x[3] - x[2], 0, np.inf),  # SPX_overnight_max > SPX_overnight_min\n",
    "    NonlinearConstraint(lambda x: x[5] - x[4], 0, np.inf)   # VIX_prior_max > VIX_prior_min\n",
    "]\n",
    "\n",
    "\n",
    "# Define initial guess (midpoints of bounds)\n",
    "x0 = [-0.05, 0.05, -0.01, 0.01, 15, 20]\n",
    "\n",
    "\n",
    "# Define the parameter space for Bayesian Optimization\n",
    "space  = [\n",
    "    Categorical(['best1bin', 'rand1bin', 'best2bin', 'rand2bin'], name='strategy'),\n",
    "    Integer(10, 20, name='popsize'),  # Population size multiplier\n",
    "    Real(0.5, 1.5, name='mutation_low'),  # Lower bound of mutation factor\n",
    "    Real(0.5, 1.5, name='mutation_high'),  # Upper bound of mutation factor\n",
    "    Real(0.5, 0.9, name='recombination')  # Recombination constant\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Decorate the objective function to use named arguments for the hyperparameters\n",
    "@use_named_args(space)\n",
    "def skopt_objective(**params):\n",
    "    print(f\"Testing parameters: {params}\")\n",
    "    \n",
    "    # Perform optimization with the current set of hyperparameters\n",
    "    result = differential_evolution(\n",
    "        objective,\n",
    "        bounds = bounds,\n",
    "        args=(target_dat,50),\n",
    "        strategy=params['strategy'],\n",
    "        maxiter=1000,\n",
    "        popsize=params['popsize'],\n",
    "        tol=1e-6,\n",
    "        mutation=(params['mutation_low'], params['mutation_high']),\n",
    "        recombination=params['recombination'],\n",
    "        seed=42,\n",
    "        disp=False,\n",
    "        constraints=constraints,\n",
    "        polish=True  # Use local search for polishing\n",
    "    )\n",
    "    \n",
    "    # Return negative WIN_RATE as objective function value (because skopt minimizes)\n",
    "    return result.fun\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "res_gp = gp_minimize(\n",
    "    skopt_objective,  # the function to minimize\n",
    "    space,  # the parameter space\n",
    "    n_calls=20,  # the number of evaluations of the objective function\n",
    "    random_state=42,  # seed for reproducibility\n",
    "    acq_func=\"EI\",  # acquisition function (Expected Improvement)\n",
    "    n_initial_points=5  # number of random points to start with\n",
    ")\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"\\nBest Hyperparameters Found:\")\n",
    "print(dict(zip([p.name for p in space], res_gp.x)))\n",
    "print(\"Best Objective Function Value (WIN_RATE):\", -res_gp.fun)  # Negative because we minimize\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
